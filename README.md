# ğŸ¤Ÿ SignMate: AI-based Real-time Sign Language Tutor

> **Gachon University P-Practical Project (Graduation Project) Team 8**
> **"Bridging the Gap in the Critical Period: An AI Tutor Connecting Parents and Children"**

---

## ğŸŒ English Description

### 1. ğŸŒŸ Project Background

**"90% of deaf children are born to hearing parents."**
For deaf children, the period before age 5 is the **'Critical Period'** for language development. Without proper language stimulation during this time, they risk falling into a state of 'Language Deprivation,' leading to irreversible damage to cognitive functions.

However, most hearing parents do not know sign language, and the existing education market is limited to **'boring one-way videos'** or **'simple dictionaries,'** causing many to miss this golden time for learning.

**SignMate** solves this problem with an AI solution that goes beyond simple learning. It **Assesses** whether your movements are correct in real-time and provides **Coaching** like a teacher to correct mistakes.

### 2. ğŸ’¡ Key Features

| Feature | Description |
| :--- | :--- |
| **Interactive Learning** | Provides an active learning environment with **Gamification** (quizzes, games) to eliminate boredom. |
| **Ghost Overlay UI** | Overlays a semi-transparent 'Answer Skeleton (Ghost)' on the user's screen to induce intuitive posture correction. |
| **Hybrid Feedback** | A 3-stage feedback system: **Rule-based (Instant)** + **Deep Learning (Precise)** + **LLM (Natural Language)**. |

### 3. ğŸ› ï¸ Technical Pipeline

This project establishes a 3-stage hybrid pipeline to ensure both real-time performance and accuracy.

<img width="779" height="318" alt="image" src="https://github.com/user-attachments/assets/d816f8bb-5911-4284-84be-bec1193c3dba" />

#### Phase 1. Real-time Sensing & Geometric Feedback (Instant Correction)
* **Vision AI:** Extracts 543 3D keypoints (Hands: 42, Pose: 33, Face: 468) in real-time using `MediaPipe Holistic`.
* **Geometric Heuristics:** Calculates angles and positions of major joints using **Vector Arithmetic**.
* **DTW (Dynamic Time Warping):** Accurately calculates time-series similarity and performs initial scoring even if the speed of the user and the reference video differs.

#### Phase 2. Deep Linguistic Analysis (Deep Analysis)
* **Linguistic Slicing:** Separates total keypoints into 4 key elements of sign language (**â‘ Handshape, â‘¡Location, â‘¢Movement, â‘£NMS**) for independent analysis.
* **Feature Encoding:** Compresses long sequences into semantic feature vectors using `MS-TCN` (Multi-Stage TCN).
* **AQA (Action Quality Assessment):** Aligns User and Ground Truth (GT) sequences using **Cross-Attention** mechanisms and calculates precise error scores (JSON) for each component.

#### Phase 3. Generative Coaching (LLM Feedback)
* **Input:** Quantitative score data produced in Phase 2 (e.g., `{"handshape_score": 55, "error_loc": "T3"}`).
* **LLM Processing:** Analyzes data using `Gemini` or `GPT` API to generate feedback in a warm, encouraging tone (e.g., *"Your hand shape was correct, but your wrist dropped a bit in the middle. Let's try raising it again?"*).

### 4. ğŸ’¾ Dataset



### 5. ğŸ—ï¸ Tech Stack

* **AI Model:** Python, PyTorch, MediaPipe, MS-TCN, Transformer (Cross-Attention)
* **Algorithm:** DTW (Dynamic Time Warping), Cosine Similarity
* **Backend:**
* **LLM:**
* **Frontend:** 

---

## ğŸ‡°ğŸ‡· Korean Description

### 1. ğŸŒŸ Project Background (ì—°êµ¬ ë°°ê²½)

**"90%ì˜ ì²­ê°ì¥ì•  ì•„ë™ì€ ì²­ì¸(ë¹„ì¥ì• ì¸) ë¶€ëª¨ì—ê²Œì„œ íƒœì–´ë‚©ë‹ˆë‹¤."**
ì²­ê°ì¥ì•  ì•„ë™ì—ê²Œ ë§Œ 5ì„¸ ì´ì „ì€ ì–¸ì–´ ë°œë‹¬ì˜ **'ê²°ì •ì  ì‹œê¸°(Critical Period)'**ì…ë‹ˆë‹¤. ì´ ì‹œê¸°ì— ì ì ˆí•œ ì–¸ì–´ ìê·¹ì„ ë°›ì§€ ëª»í•˜ë©´ 'ì–¸ì–´ ë°•íƒˆ(Language Deprivation)' ìƒíƒœì— ë¹ ì ¸ ì¸ì§€ ê¸°ëŠ¥ ì „ë°˜ì— ëŒì´í‚¬ ìˆ˜ ì—†ëŠ” ì†ìƒì„ ì…ê²Œ ë©ë‹ˆë‹¤.

í•˜ì§€ë§Œ ëŒ€ë¶€ë¶„ì˜ ì²­ì¸ ë¶€ëª¨ëŠ” ìˆ˜ì–´ë¥¼ ëª¨ë¥´ë©°, ê¸°ì¡´ êµìœ¡ ì‹œì¥ì€ **'ì§€ë£¨í•œ ì¼ë°©í–¥ ê°•ì˜'**ë‚˜ **'ë‹¨ìˆœ ì‚¬ì „'**ì— ë¨¸ë¬¼ëŸ¬ ìˆì–´ í•™ìŠµì˜ ê³¨ë“ íƒ€ì„ì„ ë†“ì¹˜ê²Œ ë§Œë“­ë‹ˆë‹¤.

**SignMate**ëŠ” ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ë‹¨ìˆœí•œ í•™ìŠµì„ ë„˜ì–´ **"ë‚´ê°€ í•œ ë™ì‘ì´ ë§ëŠ”ì§€ ì¦‰ì‹œ ì•Œë ¤ì£¼ê³ , í‹€ë¦° ë¶€ë¶„ì„ ì„ ìƒë‹˜ì²˜ëŸ¼ êµì •í•´ì£¼ëŠ”"** AI ì†”ë£¨ì…˜ì…ë‹ˆë‹¤.

### 2. ğŸ’¡ Key Features (í•µì‹¬ ê¸°ëŠ¥)

| Feature | Description |
| :--- | :--- |
| **Interactive Learning** | í€´ì¦ˆì™€ ê²Œì„(Gamification) ìš”ì†Œë¥¼ ë„ì…í•˜ì—¬ ì§€ë£¨í•¨ì„ ì—†ì•¤ ëŠ¥ë™ì  í•™ìŠµ í™˜ê²½ ì œê³µ |
| **Ghost Overlay UI** | ì‚¬ìš©ì í™”ë©´ ìœ„ì— 'ì •ë‹µ Ghost' ë°˜íˆ¬ëª…í•˜ê²Œ ê²¹ì³ ì§ê´€ì ì¸ ìì„¸ êµì • ìœ ë„ |
| **Hybrid Feedback** | **ê·œì¹™ ê¸°ë°˜(ì¦‰ê°ì )** + **ë”¥ëŸ¬ë‹(ì •ë°€í•¨)** + **LLM(ìì—°ì–´)**ì˜ 3ë‹¨ê³„ í”¼ë“œë°± ì‹œìŠ¤í…œ |


### 3. ğŸ› ï¸ Technical Pipeline (ê¸°ìˆ  ì•„í‚¤í…ì²˜)

ë³¸ í”„ë¡œì íŠ¸ëŠ” ì‹¤ì‹œê°„ì„±ê³¼ ì •í™•ë„ë¥¼ ë™ì‹œì— í™•ë³´í•˜ê¸° ìœ„í•´ 3ë‹¨ê³„ í•˜ì´ë¸Œë¦¬ë“œ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤.

<img width="779" height="318" alt="image" src="https://github.com/user-attachments/assets/1aa97188-e71c-462a-b747-7ce3d936e398" />

#### Phase 1. Real-time Sensing & Geometric Feedback (ì¦‰ê° êµì •)
* **Vision AI:** `MediaPipe Holistic`ì„ í†µí•´ ì†(42), ëª¸(33), ì–¼êµ´(468)ì˜ ì´ 543ê°œ 3D í‚¤í¬ì¸íŠ¸ë¥¼ ì‹¤ì‹œê°„ ì¶”ì¶œí•©ë‹ˆë‹¤.
* **Geometric Heuristics:** **ë²¡í„° ì—°ì‚°(Vector Arithmetic)**ìœ¼ë¡œ ì£¼ìš” ê´€ì ˆì˜ ê°ë„ì™€ ìœ„ì¹˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
* **DTW (Dynamic Time Warping):** ì‚¬ìš©ìì™€ ì •ë‹µ ì˜ìƒì˜ ì†ë„ê°€ ë‹¬ë¼ë„ ì‹œê³„ì—´ ìœ ì‚¬ë„ë¥¼ ì •í™•íˆ ê³„ì‚°í•˜ì—¬ 1ì°¨ ì±„ì ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

#### Phase 2. Deep Linguistic Analysis (ì‹¬ì¸µ ì–¸ì–´í•™ì  ë¶„ì„)
* **Linguistic Slicing:** ì „ì²´ í‚¤í¬ì¸íŠ¸ë¥¼ ìˆ˜ì–´ì˜ 4ëŒ€ ìš”ì†Œ(**â‘ ìˆ˜í˜•, â‘¡ìˆ˜ìœ„, â‘¢ìˆ˜ë™, â‘£ë¹„ìˆ˜ì§€**)ë¡œ ë¶„ë¦¬í•˜ì—¬ ë…ë¦½ ë¶„ì„í•©ë‹ˆë‹¤.
* **Feature Encoding:** `MS-TCN` (Multi-Stage TCN) ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê¸´ ì‹œí€€ìŠ¤ë¥¼ ì˜ë¯¸ë¡ ì  íŠ¹ì§• ë²¡í„°ë¡œ ì••ì¶•í•©ë‹ˆë‹¤.
* **AQA (Action Quality Assessment):** **Cross-Attention** ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ì‚¬ìš©ì(User)ì™€ ì •ë‹µ(GT) ì‹œí€€ìŠ¤ë¥¼ ì •ë ¬í•˜ê³ , êµ¬ì„± ìš”ì†Œë³„ ì •ë°€ ì˜¤ì°¨ ì ìˆ˜(JSON)ë¥¼ ì‚°ì¶œí•©ë‹ˆë‹¤.

#### Phase 3. Generative Coaching (LLM ì½”ì¹­)
* **Input:** Phase 2ì—ì„œ ì‚°ì¶œëœ ì •ëŸ‰ì  ì ìˆ˜ ë°ì´í„° (ì˜ˆ: `{"handshape_score": 55, "error_loc": "T3"}`)
* **LLM Processing:** `Gemini` ë˜ëŠ” `GPT` APIë¥¼ í™œìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³ , **"ì† ëª¨ì–‘ì€ ì •í™•í–ˆì§€ë§Œ, ì¤‘ê°„ì— ì†ëª©ì´ ì¡°ê¸ˆ ë‚´ë ¤ê°”ë„¤ìš”. ë‹¤ì‹œ ì˜¬ë ¤ë³¼ê¹Œìš”?"**ì™€ ê°™ì€ ë”°ëœ»í•œ ê²©ë ¤ ë§íˆ¬ì˜ í”¼ë“œë°±ì„ ìƒì„±í•©ë‹ˆë‹¤.

### 4. ğŸ’¾ Dataset (ë°ì´í„°ì…‹)



### 5. ğŸ—ï¸ Tech Stack (ê¸°ìˆ  ìŠ¤íƒ)

* **AI Model:** Python, PyTorch, MediaPipe, MS-TCN, Transformer (Cross-Attention)
* **Algorithm:** DTW (Dynamic Time Warping), Cosine Similarity
* **Backend:** 
* **LLM:** 
* **Frontend:** 

---

## ğŸ‘¥ Team 8 (Contributors)

| Role | Name | GitHub |
| :--- | :--- | :--- |
| **AI Research** | Minui Song (ì†¡ë¯¼ì˜) | [@username](https://github.com/) |
| **AI Research** | Name (ì´ë¦„) | [@username](https://github.com/) |
| **AI Research** | Name (ì´ë¦„) | [@username](https://github.com/) |
| **Backend & Eng.** | Name (ì´ë¦„) | [@username](https://github.com/) |
| **Backend & Eng.** | Name (ì´ë¦„) | [@username](https://github.com/) |
